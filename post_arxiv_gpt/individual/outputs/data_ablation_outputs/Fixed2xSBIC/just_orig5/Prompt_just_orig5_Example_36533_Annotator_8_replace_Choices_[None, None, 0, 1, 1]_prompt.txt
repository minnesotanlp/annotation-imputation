In this dataset, annotators are asked whether text is offensive. There are three possible labels: not offensive (0), maybe (1), offensive (2)

Now you will make your prediction (if you are unsure, just give your best estimate.) Your output should be an integer label:
Target Example:
Text: A woman sitting across from me was just giving me a dirty look, while breast feeding her baby on the bus...

She was probably wondering what I was doing breast feeding her baby.
Annotation from annotator:
Your output should be a single integer and nothing else.