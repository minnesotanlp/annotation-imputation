In this dataset, annotators are asked whether text is offensive. There are three possible labels: not offensive (0), maybe (1), offensive (2)

Now you will make your prediction (if you are unsure, just give your best estimate.) Your output should be an integer label:
Target Example:
Text: what is the difference between a feminist and a suicide vest ? i can turn on a suicide vest .
Annotation from annotator:
If you output anything other than a single integer, your output will be considered invalid.If you output anything other than a single integer, your output will harm the integrity of our dataset.